---
title: Data Generation Overview
last_modified_at: 2018-07-19
---

"The data may not contain the answer. The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data." - John Tukey  

"If you torture the data, it will confess to anything" - Ronald Coase.

Upfront consideration to the design and execution of data generation can help to prevent unfortunate or costly outcomes.  This section provides guidance on study design, human subjects research, management of clinical and experimental data, and a review of factors to consider when choosing from some of the common large scale molecular data generating platforms.

## Study Design and Funding
This section provides guidance for researchers looking to develop a hypothesis that will have reasonable statistical power, identify the appropriate set of samples, and execute a large scale data production from those samples.  
There are the two general types of studies using large scale molecular data sets, which can loosely be thought of as "investigative" and "comparative."  The two aren't completely extricable and can each can serve as groundwork for future experiments for the other.  The process to perform these types of studies, however, can be very different.  The details specific to each study type are best addressed prior to generating materials or data sets.  


* Proposals and Funding
* Hypothesis Development and Big Molecular Data
* Statistics

## IRB and Human Subjects

* Consenting and Big Molecular Data
* Privacy and Security
* De-identification
* Data Sharing and Public Repositories

## Clinical and Experimental Data
For a each study, the particular covariates associated with large scale data sets typically come from clinical or laboratory data. When these data are originating from human samples, certain protections need to be in place to ensure patient privacy.  There are resources at the Fred Hutch which can help researchers effectively manage these data so that they can be associated with downstream molecular data sets more consistently and securely.  


* Clinical Covariates
* Specimen Banking  
* Experimental Covariates

## Large-Scale Data Generation
The decisions required when generating large scale data sets themselves are informed by an understanding of the specimen cohort, any limitations imposed by the consent of the patients from which those specimens were obtained, and the specific hypothesis the researcher is intending to address.  This section includes important considerations for nucleic acid isolation and provides guidance for using the genomic platforms available at the Fred Hutch Genomics Shared Resource.  Data types generated using other large scale molecular technologies such as proteomics or metabolomics are not discussed.  


* Assay Material Prep and QC
* DNA-Based Approaches
* RNA-Based Approaches
* Genomics Platforms Available

## Laboratory Management Resources


* Support Software
* Shared Equipment and Wisdom
