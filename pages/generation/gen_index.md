---
title: Data Generation
#tags:
#keywords:
last_updated: April 25, 2018
#summary: "Landing page for Large Scale Data Generation Resources at the Fred Hutch"
sidebar: generation_sidebar
permalink: gen_index.html
layout: page
search: include
published: true
---

# Large Scale Data Generation

This would be the landing site for the first domain, for all things data generation
Large scale molecular data such as next generation sequencing or array based data is becoming ever more accessible and useful for translational research. However, while many of the fundamental aspects of biology that these tools assess are familiar, there are unique issues that arise when hundreds to thousands of data points are collected simultaneously that must be considered during the experimental design phase.  Not every question about every cohort or sample set can be answered using a given large molecular data set, and the sentiment to "sequence it and find out" can be an appealing, but ultimately risky (and costly) approach.  

## Large Scale Data and Hypothesis Development
"The data may not contain the answer. The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data." - John Tukey  

"If you torture the data, it will confess to anything" - Ronald Coase.

In this section we will provide some guidance for researchers looking to develop a hypothesis that will have reasonable statistical power and a feasible set of samples and execute a large scale data production from them.

## Study Types
There are the two general types of studies using large scale molecular data sets, which can loosely be thought of as "investigative" and "comparative."  The two aren't completely extricable and can each can serve as groundwork for future experiments for the other.  The process to perform these types of studies, however can be very different, and the details specific to each are best addressed prior to beginning a process involved in generating materials or data sets.  

## Preparing your Study Proposal
You could design a house without an architect, but the time and money you would spend while trying to do so are effectively wasted because there are people for whom this procedural and rote knowledge is their job.  The same is true for large scale molecular datasets as there is an incredible quantity of study design, sample preparation, genomics data production, bioinformatics and statistics that goes into this process. To give your study the best chance of succeeding (both in getting funding and scientifically), it's best to identify a set of collaborators familiar with the aspects of the research for which your team does not already have expertise.  

The Translational Genomics Data Coordination Center is available for collaboration in grant supported projects to provide access to a system of data management tools they manage to facilitate translational studies using large scale molecular data.  Also, we can help facilitate as-needed collaborations with various affiliated members of the Fred Hutch community with expertise in sample banking, assay material preparation, genomics data generation, bioinformatics and statistics.  If your study needs some support in these areas, we can work with you to both incorporate material into your application and also support your study over the course of the phases of research in areas where your team does not have expertise.  The project team that leads this effort has "boilerplate" NIH grant materials that we will provide after consultation to tailor the material to your particular study.  
