---
title: "Fred Hutch Wiki Home"
#tags:
#keywords:
last_updated: April 25, 2018
sidebar: home_sidebar
permalink: index.html
layout: page
---
# Introduction
This site contains a curated collection of Fred Hutch oriented documentation regarding the generation of large scale molecular data (such as genomics, transcriptomics, etc.), bioinformatics and analytics required to interpret those data, and the high performance computing infrastructure available for managing both data storage and computing tasks.  Each domain has an overview page accessible via the top navigation bar that serves as an introduction the material covered in more detail by the individual topic pages.  These materials are intended to serve as an 'on ramp' for researchers at the Fred Hutch to get up to speed on current best practices, links to on-campus resources that are relevant to a specific domain,  as well as useful links to other external content about specific topics.  This site serves as a starting place where the Fred Hutch community can document the information and resources common to many types of research happening at the Center and to communicate more effectively how to access and employ new or changing resources in an ongoing manner.  

## Overview of Content Planned
The site will include documentation in three general domains:  

### Data Generation
This section will contain information that ranges from important IRB and human subjects privacy matters that are important for large scale molecular profiling projects, through tools useful for collection of clinical, specimen and laboratory covariates, as well as the types and modes of large scale molecular data generation commonly undertaken.  

#### Data Generation Sidebar Outline

##### Study Design
###### Overview
###### Proposal Materials and Support
###### Hypothesis Development and Big Molecular Data

##### IRB and Human Subjects
###### Overview
###### Consenting and Big Molecular Data
###### Privacy and Security
###### De-identification
###### Data Sharing and Public Repositories

##### Clinical Covariates and Specimen Banking
###### Overview
###### Clinical Covariates
###### Specimen Banking
###### Laboratory Covariates
###### Nucleic Acid Omnibus

##### Laboratory and Experimental Data
###### Overview
###### Laboratory Covariates Management
###### Nucleic Acid Omnibus

##### Large Scale Data Generation
###### Overview
###### DNA Approaches
###### RNA Approaches
###### Genomics Platforms Available



You should read it if you....

### Bioinformatics
This section will contain....  

#### Bioinformatics Domain Sidebar Outline:

##### Programming and Bioinformatics
###### Overview
###### R, RStudio 
###### Bioconductor
###### Python and the Condas
###### Unix/Bash (for the command line work)
###### Other Common Languages

##### Genomics Analysis Approaches
###### Overview
###### Human Variant Calling and Analysis
###### Gene Expression and Transcript Analysis
###### Microbiome Analysis and Microbial Genomics
###### Traditional GWAS
###### Mammalian Copy Number Analysis

##### Pipelining and Workflows
###### Overview
###### Docker
###### Globus
###### AWS Batch
###### Other workflow Systems

##### Computing Platforms and Training (how to choose/know which to use/which to look up in computing domain!!)
###### Overview
###### Training Opportunities


You should read it if you....

### Scientific Computing
This section will contain...  

#### Computing Domain Sidebar Outline:

##### Access Points
###### Getting Started
All things credentials and the basics.  
###### Web-based Platforms
###### Command line-based Platforms

##### Data Storage and Access
###### Overview
Costs and basics for researchers to know
###### Privacy and Security
###### On Prem Storage
What are the systems, how are they backed up, how do you access them, PHI or no?, what compute resources connect to these storage locations and how?
###### Cloud Storage
What are the systems, how are they backed up, how do you access them, PHI or no?, what compute resources connect to these storage locations and how?

##### Compute Platforms and Access
###### Overview
####### Privacy and Security
###### Rhino
###### Gizmo
###### AWS
###### Globus Genomics
###### Other

You should read it if you...


## Contributing
### How to contribute
The documentation provided by this site is a collective project in which researchers who are both experts in some of the research domains included and perhaps novices in others contribute to both spread the labor and improve the documentation.  To facilitate the curation of content seen in this site, we have employed a GitHub repository to which any Fred Hutch based researcher can be a part of and contribute to.  The instructions for how to get started via GitHub are below.  However, we have ongoing weekly Wiki Working meetings that you can stop by and get some assistance to get set up, or just chime in with your edits, typo-finds and suggestions!  Please email Amy Paguirigan (apaguiri) if you have comments about the Wiki documentation as it stands now or if you'd like to join the group.  

#### GitHub access
In order to access the GitHub repository to provide new content or edit existing content, Fred Hutch researchers need a GitHub user account (if you do not already have one, you can [obtain one here via GitHub.](https://github.com/join)).  Once a user has a GitHub user account, access to the Fred Hutch institution and the FHBig GitHub team can be granted by IT (email Fred Hutch username scicomp and send your GitHub username to do this).  

#### Providing your contribution
We manage the content of this site via a set of markdown files that
  1. Create a branch off the master branch for your edits.  Consider naming the branch in such a way that indicates what domain the edits will primarily be in (such as "generation-typos" or "computing-newcontent").  
  2. Commit any edits or new material to only the markdown files in the "pages" directory.  
  3. Publish/push your branch to GitHub to save your work and let us know you're working on something.
  4. When done editing, create a pull request from your branch.  Suggest reviewers based on the content of the edits.
  5. Reviewers will sign off on edits by approving or providing comments on a pull request, ideally one "expert" and one "novice" based on field of expertise.  
  6. Once pull requests are merged, then any edits go live to the site [here.](https://fredhutch.github.io/wiki/)


#### Other ways to contribute:
- Be an expert or novice reviewer to one of our pull requests.
- File issues for suggested new site content.
- Take 30 minutes and find as many typo's and poor grammar as you can! #my-typo-branch

### Contributors list:
We will include a list of documentation contributors here.  Considering a report generated from the GitHub repo commit data.  
